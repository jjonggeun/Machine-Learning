# 배치사이즈 (Batch Size):

# 배치사이즈는 한 번의 가중치 업데이트를 위해 사용하는 데이터 샘플의 수를 나타냅니다.
# 배치사이즈가 5라는 것은, 5개의 데이터 샘플마다 한 번씩 가중치가 업데이트된다는 의미입니다.
# 에폭 (Epoch):

# 에폭은 전체 데이터셋이 한 번 학습되는 과정을 나타냅니다.
# 에폭이 200이라는 것은, 전체 데이터셋을 200번 반복해서 학습한다는 의미입니다.
# 실행 횟수 계산
# 총 샘플 수:

# 예를 들어, 훈련 데이터셋의 총 샘플 수가 100개라고 가정하겠습니다.
# 배치의 수:

# 배치사이즈가 5이므로, 한 에폭당 배치의 수는 총 샘플 수를 배치사이즈로 나눈 값입니다.
# 따라서, 100개의 샘플을 5개의 배치로 나누면, 한 에폭당 20개의 배치가 생깁니다.
# 가중치 업데이트 횟수:

# 한 에폭당 20번의 가중치 업데이트가 발생합니다.
# 에폭이 200번이므로, 전체 학습 과정에서 20 * 200 = 4000번의 가중치 업데이트가 발생합니다.
# 학습 과정 설명
# 데이터 준비:

# 전체 데이터셋을 배치사이즈 5로 나누어, 한 에폭당 20개의 배치를 만듭니다.
# 순전파 (Forward Propagation):

# 각 배치에 대해 입력 데이터를 은닉층과 출력층을 거쳐 최종 출력 값을 계산합니다.
# 역전파 (Backward Propagation):

# 출력 값과 실제 값의 오차를 계산하고, 이를 통해 가중치의 경사를 구합니다.
# 가중치 업데이트 (Weights Update):

# 경사 값을 학습률과 함께 사용하여 가중치를 업데이트합니다.
# 이 과정이 배치당 1번씩, 한 에폭당 20번 발생합니다.
# 에폭 반복:

# 전체 데이터셋을 1번 학습하는 것을 1 에폭이라고 하며, 이를 200번 반복합니다.
# 따라서, 전체 데이터셋을 200번 반복하여 학습합니다.
# 정리
# 배치사이즈가 5이고 에폭이 200으로 설정되면, 전체 학습 과정에서 총 4000번의 가중치 업데이트가 발생합니다.
# 이는 배치사이즈가 작을수록, 각 에폭당 더 많은 가중치 업데이트가 발생함을 의미합니다.
# 배치사이즈가 작을 때는 모델이 더 자주 가중치를 업데이트하여 빠르게 학습할 수 있지만, 각 업데이트마다 계산이 더 작고, 더 많은 업데이트를 통해 전체 학습 과정이 길어질 수 있습니다.
# 에폭 수가 많을수록, 모델은 전체 데이터셋을 더 많이 반복하여 학습하며, 이는 더 많은 학습 기회를 제공하여 모델 성능을 향상시킬 수 있습니다.
#=========================================================================================================================================================================
# 코드 전체 설명
# 라이브러리 임포트:

# numpy: 수치 연산을 위한 라이브러리입니다.
# pandas: 데이터 처리를 위한 라이브러리입니다.
# matplotlib.pyplot: 데이터 시각화를 위한 라이브러리입니다.
# 시그모이드 함수 정의:

# sigmoid(x): 시그모이드 함수는 입력 값을 0과 1 사이의 값으로 변환합니다.
# sigmoid_derivative(x): 시그모이드 함수의 미분 값은 경사 하강법에서 사용됩니다.
# 순전파 함수 정의:

# forward_propagation(x_with_dummy, v, w): 순전파를 수행하여 중간 값들과 최종 출력 값을 반환합니다.
# A: 입력 데이터와 은닉층 가중치의 선형 결합입니다.
# b: A에 시그모이드 함수를 적용한 값입니다.
# b_with_dummy: b에 더미 데이터를 추가한 값입니다.
# B: 은닉층 출력과 출력층 가중치의 선형 결합입니다.
# y_hat: B에 시그모이드 함수를 적용한 최종 출력 값입니다.
# 역전파 함수 정의:

# backward_propagation(x_with_dummy, y_one_hot, A, b, b_with_dummy, B, y_hat, v, w): 역전파를 수행하여 출력층과 은닉층 가중치의 경사를 반환합니다.
# error: 출력 값과 실제 값의 오차입니다.
# wmse: 출력층 가중치의 경사로, 출력층 가중치의 업데이트에 사용됩니다.
# vmse: 은닉층 가중치의 경사로, 은닉층 가중치의 업데이트에 사용됩니다.
# 데이터 분할 함수 정의:

# aug_data(data, train_ratio, test_ratio): 데이터를 훈련 세트와 테스트 세트로 분할합니다.
# train_ratio와 test_ratio의 합은 1이어야 합니다.
# 데이터를 랜덤하게 섞은 후, 지정된 비율로 훈련 세트와 테스트 세트로 분할합니다.
# 데이터 불러오기:

# fold_dir: 데이터를 저장한 파일 경로입니다.
# pd.read_csv(fold_dir): 파일을 읽어와 데이터프레임으로 변환합니다.
# temp_data.to_numpy(): 데이터프레임을 numpy 배열로 변환합니다.
# 데이터 분할:

# train_data, test_data = aug_data(temp_data, 0.7, 0.3): 데이터를 7:3 비율로 훈련 세트와 테스트 세트로 분할합니다.
# 데이터 분리:

# x_train: 훈련 세트의 입력 데이터입니다.
# y_train: 훈련 세트의 타겟 데이터입니다.
# x_test: 테스트 세트의 입력 데이터입니다.
# y_test: 테스트 세트의 타겟 데이터입니다.
# 입력 속성 수와 출력 클래스 수 추출:

# M: 입력 데이터의 속성 수입니다.
# output_size: 출력 클래스 수입니다.
# 은닉층의 노드 수 설정:

# hidden_size = 10: 은닉층의 노드 수를 10으로 설정합니다.
# 가중치 초기화:

# v: 입력층에서 은닉층으로의 가중치입니다.
# w: 은닉층에서 출력층으로의 가중치입니다.
# 학습 파라미터 설정:

# learning_rate = 0.1: 학습률을 0.1로 설정합니다.
# epochs = 200: 학습 에포크 수를 200으로 설정합니다.
# batch_size = 5: 배치 사이즈를 5로 설정합니다.
# One-Hot Encoding:

# y_train_one_hot: y 데이터를 One-Hot 인코딩으로 변환할 배열을 초기화합니다.
# 각 샘플의 y값에 해당하는 위치를 1로 설정합니다.
# 데이터에 더미 변수 추가:

# x_train_with_dummy: x_train 데이터에 더미 변수를 추가합니다.
# x_test_with_dummy: x_test 데이터에 더미 변수를 추가합니다.
# 정확도와 MSE를 저장할 리스트 초기화:

# accuracy_list: 정확도 기록 리스트입니다.
# mse_list: MSE 기록 리스트입니다.
# 최적의 가중치를 저장할 변수 초기화:

# best_accuracy: 최적의 정확도입니다.
# best_v: 최적의 입력층-은닉층 가중치입니다.
# best_w: 최적의 은닉층-출력층 가중치입니다.
# 학습:

# 지정된 에포크 수만큼 반복합니다.
# 배치 크기 단위로 훈련 데이터를 반복합니다.
# 현재 배치에 해당하는 입력 데이터와 타겟 데이터를 추출합니다.
# 배치 데이터에 대해 순전파를 수행하여 예측 값을 계산합니다.
# 순전파 결과를 바탕으로 역전파를 수행하여 경사를 계산합니다.
# 학습률을 곱한 경사 값을 빼서 가중치를 업데이트합니다.
# 테스트 데이터에 대해 순전파를 수행하여 예측 값을 계산합니다.
# 예측 값에서 최대값의 인덱스를 구하고, 실제 값과 비교하여 정확도를 계산합니다.
# 테스트 정확도가 최적의 정확도보다 높으면, 현재 가중치를 최적 가중치로 저장합니다.
# 전체 훈련 데이터에 대해 순전파를 수행하여 예측 값을 계산합니다.
# 예측 값에서 최대값의 인덱스를 구하고, 실제 값과 비교하여 정확도를 계산합니다.
# 현재 에포크의 정확도를 리스트에 기록합니다.
# 예측 값과 실제 값의 제곱 오차의 평균(MSE)을 계산합니다.
# 현재 에포크의 MSE를 리스트에 기록합니다.
# 최적의 가중치로 모델 업데이트:

# 학습이 완료되면 최적의 정확도를 얻은 가중치(best_v, best_w)로 모델을 업데이트합니다.
# 혼동 행렬 계산 함수 정의:

# compute_confusion_matrix(y_true, y_pred, num_classes): 예측 값과 실제 값을 비교하여 혼동 행렬을 계산합니다.
# 예측 값으로 혼동 행렬 계산:

# confusion_matrix = compute_confusion_matrix(y_test, y_hat_test_index, output_size): 예측 값으로 혼동 행렬을 계산합니다.
# 혼동 행렬 출력:

# print(confusion_matrix): 혼동 행렬을 출력합니다.
# 그래프 출력:

# plt.figure(figsize=(18, 6)): 그래프 크기를 설정합니다.
# 정확도 그래프를 그립니다.
# plt.subplot(1, 2, 1): 두 개의 서브플롯 중 첫 번째 플롯을 설정합니다.
# plt.plot(range(1, epochs+1), accuracy_list, label='Accuracy', color='blue'): 정확도 그래프를 그립니다.
# plt.xlabel('Epochs'): x축 레이블을 설정합니다.
# plt.ylabel('Accuracy'): y축 레이블을 설정합니다.
# plt.title('Accuracy over epochs'): 그래프 제목을 설정합니다.
# plt.legend(): 범례를 추가합니다.
# plt.grid(True): 그리드를 추가합니다.
# plt.ylim(0, 1): y 축 범위를 설정합니다.
# MSE 그래프를 그립니다.
# plt.subplot(1, 2, 2): 두 개의 서브플롯 중 두 번째 플롯을 설정합니다.
# plt.plot(range(1, epochs+1), mse_list, label='MSE', color='red'): MSE 그래프를 그립니다.
# plt.xlabel('Epochs'): x축 레이블을 설정합니다.
# plt.ylabel('MSE'): y축 레이블을 설정합니다.
# plt.title('MSE over epochs'): 그래프 제목을 설정합니다.
# plt.legend(): 범례를 추가합니다.
# plt.grid(): 그리드를 추가합니다.
# plt.ylim(0, 1): y 축 범위를 설정합니다.
# plt.show(): 그래프를 출력합니다.
#===========================================================================================================
# import numpy as np  # 수치 연산을 위한 라이브러리
# import pandas as pd  # 데이터 처리를 위한 라이브러리

# # 파일 경로 설정
# a_xdata_path = "path/to/A_xdata.csv"
# a_ydata_path = "path/to/A_ydata.csv"
# b_xdata_path = "path/to/B_xdata.csv"
# b_ydata_path = "path/to/B_ydata.csv"

# # 데이터 불러오기
# a_xdata = pd.read_csv(a_xdata_path).to_numpy()  # A_xdata를 numpy 배열로 변환
# a_ydata = pd.read_csv(a_ydata_path).to_numpy()  # A_ydata를 numpy 배열로 변환
# b_xdata = pd.read_csv(b_xdata_path).to_numpy()  # B_xdata를 numpy 배열로 변환
# b_ydata = pd.read_csv(b_ydata_path).to_numpy()  # B_ydata를 numpy 배열로 변환

# # 데이터 결합
# a_data = np.hstack((a_xdata, a_ydata))  # A 데이터의 x와 y를 수평으로 결합
# b_data = np.hstack((b_xdata, b_ydata))  # B 데이터의 x와 y를 수평으로 결합

# np.vstack: 배열을 수직(vertically)으로 쌓아 새로운 배열을 만듭니다.
# np.hstack: 배열을 수평(horizontally)으로 쌓아 새로운 배열을 만듭니다.
#=================================================================================================================
# np.random.rand
# np.random.rand 함수는 0과 1 사이의 균일 분포(uniform distribution)에서 무작위 수를 생성합니다. 이 함수는 주어진 형태(shape)의 배열을 생성하며,
#   배열의 모든 요소는 0 이상 1 미만의 실수로 무작위로 채워집니다.
#   np.random.randn
# np.random.randn 함수는 평균이 0이고 표준편차가 1인 표준 정규 분포(standard normal distribution)에서 무작위 수를 생성합니다. 
# 이 함수도 주어진 형태(shape)의 배열을 생성하며, 배열의 모든 요소는 정규 분포를 따르는 실수로 무작위로 채워집니다.